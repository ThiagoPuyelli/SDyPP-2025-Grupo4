# TP Nro 3 - Sistemas Distribuidos y Programacion Paralela

## Video presentacion
[Video](https://youtu.be/0WL-X8g0s3M)

### Integrantes:
* Puyelli, Thiago
* Herrneder, Matias

## Consigna
Trabajo PrÃ¡ctico NÂº 3
ComputaciÃ³n en la Nube (Kubernetes / RabbitMQ)
Fecha de Entrega: 11/05/25
(todos los puntos)

En la nube, tengo 2 patrones de trabajo.
Cloud Native (corre 100 % en la nube).
HÃ­brido (parte en equipos locales / Onpremise - Cloud)

Ahora, pensemos la nube como una extensiÃ³n de la capacidad de cÃ³mputo de su/sus equipo/s. De esta manera, logramos aplicar el patrÃ³n de Cloud-Bursting. 

Por ejemplo, si tenemos una aplicaciÃ³n Cliente/Servidor (HTTP, gRPC, WSS) como por ejemplo filtro Sobelâ€¦â€¦..

#HIT 1 - El operador de Sobel es una mÃ¡scara que, aplicada a una imagen, permite detectar (resaltar) bordes. Este operador es una operaciÃ³n matemÃ¡tica que, aplicada a cada pixel y teniendo en cuenta los pÃ­xeles que lo rodean, obtiene un nuevo valor (color) para ese pixel. Aplicando la operaciÃ³n a cada pÃ­xel, se obtiene una nueva imagen que resalta los bordes.
Objetivo: 
Input: una imagen. 
proceso (Sobel).
output: una imagen filtrada.
Parte1 
Desarrollar un proceso centralizado que tome una imagen, aplique la mÃ¡scara, y genere un nuevo archivo con el resultado. 

Parte2 
Desarrolle este proceso de manera distribuida donde se debe partir la imagen en n pedazos, y asignar la tarea de aplicar la mÃ¡scara a N procesos distribuidos. DespuÃ©s deberÃ¡ unificar los resultados. 

A partir de ambas implementaciones, comente los resultados de performance dependiendo de la cantidad de nodos y tamaÃ±o de imagen.

Parte3 
Mejore la aplicaciÃ³n del punto anterior para que, en caso de que un proceso distribuido (al que se le asignÃ³ parte de la imagen a procesar - WORKER) se caiga y no responda, el proceso principal detecte esta situaciÃ³n y pida este cÃ¡lculo a otro proceso.

Bien, todo eso lo corrieron â€œdistribuidoâ€ pero â€œcentralizadoâ€ en su propia computadora. Sin embargo, la necesidad de procesamiento para aplicar un filtro sobre imÃ¡genes (que pueden ser muy grandes) puede generar que nos encontramos con un tope de capacidad de cÃ³mputo (mÃ¡s allÃ¡ que lo hayamos construido de forma redundante), Â¿QuÃ© opciones tenemos?
Si es local, agregar mÃ¡s nodos de trabajo. Sin embargo, como discutimos, eso requiere tiempo (compra, ambientaciÃ³n, espacio e instalaciÃ³n de paquetes) y produce un Costo Fijo mÃ­nimo (mÃ¡s allÃ¡ del variable por intensidad de uso). 

Hacer un offloading a la nube. La cual trabajaremos en este apartado. 

#HIT 2 - Sobel con offloading en la nube ;) para construir una base elÃ¡stica (elÃ¡stica):
Mismo objetivo de calcular sobel, pero ahora vamos a usar Terraform para construir nodos de trabajo cuando se requiera procesar tareas y eliminarlos al terminar. Recuerde que serÃ¡ necesario:
Instalar con #user_data las herramientas necesarias (java, docker, tools, docker).
Copiar ejecutable (jar, py, etc) o descargar imagen Docker (hub).
Poner a correr la aplicaciÃ³n e integrarse al cluster de trabajo.

El objetivo de este ejercicio es que ustedes puedan construir una arquitectura escalable (tipo 1, inicial) HÃBRIDA. Debe presentar el diagrama de arquitectura y comentar su decisiÃ³n de desarrollar cada servicio y donde lo â€œcolocaâ€.


#HIT 3 - Sobel contenerizado asincrÃ³nico y escalable (BASE DE TP FINAL) 

A diferencia del clÃºster anterior, la idea es que construya una infraestructura basada en la nube pero ahora con un enfoque diferente. 

Para ello, serÃ¡ necesario:

Desplegar con terraform un cluster de Kubernetes (GKE). 

Este serÃ¡ el manejador de todos los recursos que vayamos a desplegar. Es decir, va a alojar tanto los servicios de infraestructura (rabbitMQ y Redis) como los componentes de las aplicaciones que vamos a correr (frontend, backend, split, joiner, etc). Este clÃºster tiene que tener la siguiente configuraciÃ³n mÃ­nima
Un nodegroup para alojar los servicios de infraestructura (rabbitmq, redis, otros)
Un nodegroup compartido para las aplicaciones del sistema (front, back, split, joiner)
MÃ¡quinas virtuales (fuera del cluster)  que se encarguen de las tareas de procesamiento / cÃ³mputo intensivo. 


Construir los pipelines de despliegue de todos los servicios.

Pipeline 1: El que construye el Kubernetes. 
Pipeline 1.1: El que despliega los servicios (base datos - Redis, sistema de colas - RabbitMQ)
Pipeline 1.2-1.N: De cada aplicaciÃ³n desarrollada (frontend, backend, split, join)
Pipeline 2: Despliegue de mÃ¡quinas virtuales para construir a los workers. Objetivo deseable: Que estas mÃ¡quinas sean â€œdinÃ¡micasâ€.  



#HIT3 - AnÃ¡lisis de DesempeÃ±o Bajo Carga

Para evaluar el desempeÃ±o de la plataforma, se analizarÃ¡n los tiempos de respuesta en diferentes escenarios de carga, modificando las siguientes variables:

TamaÃ±o de los datos (V1): Se utilizarÃ¡n tamaÃ±os representativos de carga, tales como 1 KB, 10 KB, 1 MB, 10 MB y 100 MB.
Cantidad de peticiones concurrentes (V2): Se simularÃ¡n diferentes niveles de concurrencia.
Cantidad de workers (V3): Se ajustarÃ¡ el nÃºmero de procesos o threads disponibles para manejar las peticiones.

âš¡Disclaimer: Si quiere lograr usar mÃ¡s nodos, use nodos en distintas regiones ðŸ™‚

El objetivo es comprender cÃ³mo la plataforma responde al modificar estas variables, permitiendo identificar su capacidad de escalabilidad y posibles puntos de mejora. Los resultados se presentarÃ¡n en una tabla que muestre los tiempos de respuesta obtenidos en cada combinaciÃ³n de las variables, proporcionando una visiÃ³n clara de la evoluciÃ³n del desempeÃ±o bajo diferentes condiciones de carga.

## Consideraciones generales:
Cada ejercicio (Hit) tiene su propio readme con instrucciones y especificaciones puntuales del ejercicio, en rasgos generales, se empezÃ³ en el Hit#1 planteando una infraestructura que resolviera de forma distribuida el problema de aplicar un filtro sobel a una imagen, partiendo dicha imagen y paralelizando su procesamieno en distintas mÃ¡quinas, a travÃ©s de uso de docker.  
Luego, en el Hit#2, se avanzo a una estructura de cloud, donde se implementa todo el procesamiento en la nube (gcp), automatizando el despliegue con kubernetes.  
Finalmente, en el Hit#3, se implementa un sistema hibrido, donde si bien se sigue manteniendo gcp para el total del procesamiento, las tareas asociadas a workers y la aplicacion de los filtros, se realizan en maquinas virtuales (fuera del cluster de kubernetes), que no necesariamente tendrian que estar en gcp.

## Como utilizar la aplicaciÃ³n:
Para utilizar la aplicaciÃ³n, se debe realizar una peticiÃ³n HTTP GET con el formato: 
>http://{ip}/sobel?image_url={url_a_imagen_en_internet}&n_parts={cantidad_de_particiones_para_procesar}

Ejemplo:
```
http://34.138.218.127/sobel?image_url=https://imgs.search.brave.com/VyMDMutzQJTOYQZjnv9yhXb1NfyicOiLlexCkDe58KU/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly9zMS5z/aWduaWZpY2Fkb3Mu/Y29tL2ZvdG8vaW1h/Z2VuLWluaWNpby1j/a2UuanBnP2NsYXNz/PWFydGljbGU
```
```
http://34.138.218.127/sobel?image_url=https://imgs.search.brave.com/KpE6aao3PDrF0b5DYZhG4fYQMxSnrNSS43-VCt1n6LQ/rs:fit:860:0:0:0/g:ce/aHR0cHM6Ly9jZG4z/LnBpeGVsY3V0LmFw/cC91cHNjYWxlX2Fm/dGVyXzJfNWY3N2Rh/YjkwYy5qcGc&n_parts=6
```

Para recuperar la imagen se usa el link que vuelve en la respuesta de la peticion, algo del estilo
>http://{ip}/get_image/{imagen_id}

Ejemplo:
```
http://34.138.218.127/get_image/8e55b9e8-9eb1-4c39-bd25-bf5a0e591164
```

## ATENCION
Por el momento solo se aceptan imagenes en formato .jpg